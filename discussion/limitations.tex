\section*{Limitations}
\addcontentsline{toc}{section}{\protect\numberline{}Limitations}

% +asymptotic analysis
Our presented method has several limitations:
\begin{enumerate}
  \item \emph{Complex regions trigger quadratic search.} Since it is unlikely
        that edit distance in general can be solved in strongly subquadratic
        time, it is inevitable that there are inputs for which our approach
        requires quadratic time.  In particular, regions with high error rate,
        long indels, and too many matches~(\cref{GLOBALsec:limitations}) are
        challenging and trigger quadratic exploration.
  \item \emph{High constant in runtime complexity.} Despite the near-linear
        scaling of the number of expanded states~(\cref{GLOBALsec:expanded}),
        \astarpa only outperforms \edlib and \wfa for sufficiently long sequences
        (~\cref{GLOBALfig:scaling-n}) due to the relatively high computational constant
        that the \A search induces.
  \item \emph{Complex parameter tuning.} The performance of our approach
        depends heavily on the sequences to be aligned and the corresponding choice of
        parameters (whether to use chaining, the seed length $k$, and whether to use
        inexact matches $\spot$). The parameter tuning (currently
        very simple~(\cref{GLOBALsec:evals-setup}) may require a more comprehensive
        framework when introducing additional optimizations.
\end{enumerate}

% issue
The seed heuristic, which is in the core of our \A algorithm, is admissible
(optimistic) but not consistent (monotone). As a consequence, any of the
quadratic number of state can be expanded multiple times, which could
theoretically lead to over-quadratic scaling. In practice, repeated expansions
happen but the empirical scaling is preserved near-linear as long as the number
of seed matches is near-linear and the seed heuristic is capable of compensating
for the errors.

% theory
An alternative theoretical analysis would consider the average case (expected)
scaling of our algorithms under a data model. An imaginable result would look
like a connection between the sequence lengths, error rate, and the algorithm
steps (mostly dependant on the number of seed matches and the number of expanded
states). To construct such a connection, a heuristic function will have to be
chosen among a class of seed heuristics (\AG with certain seed length, allowed
number of errors in seed matches, etc.).
