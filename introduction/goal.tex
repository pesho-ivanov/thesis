\section*{Motivation}
\addcontentsline{toc}{section}{\protect\numberline{}{Motivation}}

We motivate this thesis by the importance of optimality guarantees, the
existence of unused information for scaling improvements, and the existance of
informed search algorithms that can be heuristically fast and provably optimal.
Additionally, novel alignment algorithms are useful in the modern pangenomics
setting.

\subsection*{Practical read aligners are approximate}

Current practical semi-global aligners are either vague about the metrics they
optimize or they do not guarantee optimality~\cite{alser2021technology}. An
approximate algorithm can produce wrong results either because it did not
succeed in optimizing its objective function or because it was aiming at a poor
objective function. Requiring the solutions to be optimal according the an
objective, would eliminate the former issue and focus the research on the
latter.

Sequence alignment is an early step in most bioinformatics pipelines, so
incorrect alignments can cause biases in downstream analyses. For instance, the
combination of high variability of MHC sequences in humans and small differences
between alleles~\cite{buhler_hla_2011} leads to a risk of misclassifications due
to suboptimal alignment. Guaranteeing optimal alignment against all variations
represented in a graph would be a major step towards alleviating those biases.

While heuristic algorithms usually find the correct alignment for simple
references, they often perform poorly in regions of very high complexity, such
as in the human major histocompatibility complex
(MHC)~\cite{dilthey_improved_2015}, in complex but rare genotypes arising from
somatic-subclones in tumor sequencing data~\cite{harismendy_detection_2011}, or
in the presence of frequent sequencing errors~\cite{salmela_lordec_2014}. Thus,
the produced results are doubted.

\subsection*{Optimal aligners are slow}

There is a fundamental trade-off between perforamance and optimality guarantees:
an algorithm that is allowed suboptimality may exploit the lesser restrictions
for better performance. Given the worst-case analysis requiring near-quadratic
runtime even to compute edit distance exactly~\citep{backurs2015edit}, it is
understandable why most scholars are skeptical about faster optimal algorithms.

For semi-global sequence-to-sequence alignment, a common consensus seems to be
that optimal algorithms are infeasible for read alignment, especially for long
reads. All production read aligners following the approximate seed-extend
paradigm~\cite{alser2021technology}\footnote{This study examines 107 aligners.}.

Existing optimal sequence-to-graph aligners rely on dynamic programming (DP) and
always reach quadratic worst-case asymptotic runtime~\citep{equi2019complexity}.
Such aligners include \vargas~\citep{darby2020vargas},
\pasgal~\citep{jain_accelerating_2019},
\graphaligner~\citep{rautiainen_bitparallel_2019},
\hga~\citep{feng2021accelerating}, and \vg~\citep{garrison_variation_2018},
which focus on bit-level optimizations and parallelization to futher increase
their throughput.

For global alignment, optimal algorithms are nevertheless used in practice,
despite of their quadratic scaling. The ongoing competition between the optimal
aligners employs both algorithmic advancements and implementation optimizations
on caching, bit-parallelization, GPU.~(\cref{ch:global}).

Even for related sequences, the fastest optimal
global~\citep{marco2021fast,vsovsic2017edlib} and semi-global
aligners~\citep{rautiainen_bitparallel_2019} scale quadratically when the edit
distance increases with the length, which is the case for sequencing errors and
biological variation. In the age of big data and long reads (e.g. PacBio, ONP),
this quadratic scaling with length is prohibitive, so the algorithms with
practical usage (e.g. minimap2, bwt, kallisto) do not guarantee optimality but
run in subquadratic time~\citep{kucherov2019evolution}. This is a computational
bottleneck given the growing amounts of biological data and the increasing
sequence lengths~\citep{kucherov2019evolution}. For each type of sequence
alignment (e.g. global and semi-global), a tradeoff exists between amount of
computation and the alignment accuracy.

The gap between fast and optimal global alignment has been recognized but no
optimal algorithms are known that run subquadratically for related
sequences~\citep{medvedev2022theoretical}.

\subsection*{Room for performance improvement for optimal alignment}

The following observations demonstrate room for improvement for the expected
runtime for optimal semi-global and global alignment. Moreover they hint towards
information that is currently not harnessed for the average case:

\begin{observation}
    The output of the alignment problem is linear in the input size.
\end{observation}

\begin{observation}
    Optimal global alignment takes linear time if only substitutions are allowed.
\end{observation}

\begin{observation}
    Approximate aligners scale better and run faster than optimal.
\end{observation}

\begin{observation}
    Existing optimal algorithms for semi-global alignment are near-quadratic not
    only in the worst case but also for related sequences.
\end{observation}

\begin{observation}
    The quadratic DP to global alignment (Needleman-Wunsch) also solves the more
    complex semi-global and local alignment (Smith-Waterman).
\end{observation}

\begin{paradox}
    A long query has more information that may hint towards the best semi-global
    alignment position in a reference but all optimal algorithms are strictly
    slower for longer sequences.
\end{paradox}

\begin{observation}
    The existing optimal aligners choose next step based only on
    previous~(prefix) information and ignore the remaining~(suffix).
\end{observation}

These observations and paradoxes shape the main question of this thesis:

\begin{problem}
    Can we design more scalable and faster algorithms for optimal alignment of
    \emph{related} sequences?
\end{problem}

\subsection*{\A can harness the heuristic speed and provable optimality}

Algorithm correctness is arguably a useful property which is often not simple to
guarantee. It can undoubtedly improve accuracy, especially in the case of
complex data. But finding an optimal alignment requires a conceptually different
approach than finding an approximate alignment. Instead of finding \emph{one}
good alignment, finding an optimal alignment requires proving that \emph{all}
other exponentially-many alignments are not better.

The optimal algorithms used in computational biology explore the search space of
possible alignments in an uninformed fashion: by aligning a prefix of one
sequence to a prefix of the other. This contrasts with the informed search
algorithms such as the algorithm by~\citet{hunt1977fast} solving the longest
common subsequence (LCS) problem (a special case of the edit distance
alignment). Sequence alignment can naturally be formulated as a shortest path
problem solvable by Dijkstra's algorithm~\citep{ukkonen1985algorithms}. \A is an
\emph{informed search} algorithm that generalizes Dijkstra's
algorithm~\citep{hart1968formal}. \A has not been successfully applied to
sequence alignment but it may lead the path solving ``a major open problem to
implement an algorithm with linear-like empirical scaling on inputs where the
edit distance is linear in n''~\citep{medvedev2022theoretical}.

\subsection*{Alignment shifts towards pangenomics}

The benefits of using graph references representing biological variation have
been demonstrated to increase the alignment
quality~\citep{garrison_variation_2018}. The transition towards graph references
only aggravates the computational issues owing to the potentially complex graph
topology~\citep{equi_complexity_2019}. The interest towards genome graphs keeps
increasing with the first International Genome Graph Symposium being held this
year in Ascona, Switzerland (2022).
