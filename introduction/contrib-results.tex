\subsection*{Results}

We empirically demonstrate the superior scaling and performance of the
semi-global aligner \astarix and the global aligner \astarpa to other optimal
alignment algorithms.

\paragraph{Worst case vs related sequence}
Traditionally, the runtime and memory have been analysed for the worst case
asymptotic behavior of the algorithm. Since the near quadratic worst case
asymptotics is likely to be tight for both global~\citep{backurs2015edit} and
semi-global alignment, we targete related sequences (by limiting their
per-letter error rate), and estimate their empyric runtime and memory scaling.

\paragraph{Setting}
We demontrate that the additional information from the whole sequence can
improve the scaling with query length, reference size and error rate,
substantially decrease the necessary computations, and result in algorithms that
are orders of magnitude faster than existing optimal algorithms. Our empyrical
analysis of scaling is done by repeatedly running the same algorithm on
increasingly more complex input data (longer sequences, higher error rate). This
approach is useful to estimate the scaling of the algorithm and its
implementation. Note that these scaling analyses are not asymptotical, includes
noise (of measurements and best-fit estimations), is not trivially applicable to
more than 1 dimensions.

% regimes
Our algorithms seem to follow any of the scaling regimes, based on the
capability of the seed heuristic to compensate for all the errors.

% speculations
Based on the empitical evaluations and the intuition behind the algorithms, we
speculate that the sequence length until which our algorithms can scale
near-linearly, can be exponentially increased by lowering the error rate. For
the semi-global alignment, any unit of alignment cost that is not compensated by
the potential of the seed heuristic, leads to a deeper exploration of the trie,
which is grows exponentially until it saturate to quadratic.

\paragraph{Scaling with reference size}
In~\cref{ch:trie} we present the tool \astarix which applies the \A algorithm to
find optimal alignments, based on a domain-specific heuristic and enhanced by
multiple algorithmic optimizations. Importantly, our approach allows for both
cyclic and acyclic graphs including variation and de Bruijn graphs. We
demonstrate that using a trie index we can achieve sublinear scaling of aligning
runtime with reference size, and that \A can scale exponentially better than
\dijkstra with increasing (but small) number of errors in the reads. Moreover,
for short reads, both \astarix and \dijkstra scale better and outperform current
state-of-the-art optimal aligners with increasing genome graph size.
Nevertheless, scaling optimal alignment of long reads on big graphs remained an
open problem.

\paragraph{Scaling with query length}
In~\cref{ch:seed} we upgrade \astarix with a novel \sh which guides the \A
search by preferring crumbs on nodes that lead towards optimal alignments even
for long reads. This approach enables the near-linear scaling of semi-global
alignment with read length. On our linear and variation graph datasets, 99.99\%
of the states are skipped due to the accurate heuristic function.

\paragraph{Scaling with error rate}
In~\cref{ch:global} we resolve the third major bottleneck---handling high error
rates. We presented an algorithm with an implementation in \astarpa solving
pairwise alignment between two sequences. The algorithm is based on \A with a
\sh, inexact matching, match chaining, and match pruning, which we proved to
find an exact solution according to edit distance. For random sequences with up
to $15\%$ uniform errors, the runtime of \astarpa scales near-linearly to very
long sequences ($10^7\bp$) and outperforms other exact aligners. We demonstrate
that on real ONT reads from a human genome, \astarpa is faster than other
aligners on only a limited portion of the reads.

As it turns out, when the error rate is limited, our optimal solutions
empirically scale near-linearly up to very long sequences. This translates to
many orders of magnitude of runtime speedup compared to state-of-the-art optimal
aligners.

Interestingly, no matches are required for the near-linear behavior of the seed
heuristic.