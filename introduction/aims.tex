\section*{Motivation and research aims}
\addcontentsline{toc}{section}{\protect\numberline{}{Motivation and research aims}}

A major importance for our apporach is to borrow the concept of seeds but apply
it in a novel way: instead of finding alignments around seed matches, we use the
lack of matches to penalize alignments by desigining the \emph{seed heuristic}
that drive the \A search. Seeds are cousins of kmers which are popular in
sequence alignment since de Bruijn Graphs were applied for genome assembly.
Further kmers are cousins of ngrams which are popular in computational
linguistics since .

It may be surprising that a novel approach to alignment appears 60 years after
the problem was first efficiently solved. Nevertheless, 

Here we speculate about the possible
reasons for it: focus on new technology and data, not believing that optimal
solutions could be efficient.

%combining several existing ideas new (\A, trie, seeds)

All optimal algorithms for semi-global alignment have to iterate over the whole
reference for each query. We should be able to optimize this by precomputation.

\begin{problem}
    What is the computational complexity of global and semi-global alignment of
    related sequences under edit distance?
\end{problem}

The runtime of global alignment scales near-quadratically in general, but
linearly when there there are no errors. It is unknown how the error rate
influences the expected runtime.

Global alignment is still considered an open problem since it is still not known
whether exact pairwise alignment is possible in linear time for related
sequences~\citep{medvedev2022theoretical}. 

On the other hand all optimal solutions are near-quadratic and the theoretical
limit is near-quadratic. To spead up beyond this near-quadratic barrier, current
practical algorithms break the optimality guarantee hoping that the produced
alignments are accurate enough. 

%But it is possible to be fast and accurate in the same time?
We take another approach: we preserve the optimality guarantee and use
substantially more information with the hope to be fast enough. As it turns out,
when the error rate is limited, our optimal solutions empirically scale
near-linearly up to very long sequences. This translates to many orders of
magnitude of runtime speedup compared to state-of-the-art optimal aligners.

% Problem, applications
The problem of aligning one biological sequence to another has been formulated
over half a century ago~\citep{needleman1970general} and is known as
\emph{global pairwise alignment}~\citep{navarro2001guided}. Pairwise alignment
has numerous applications in computational biology, such as genome assembly,
read alignment, variant detection, multiple sequence alignment, and differential
expression~\citep{prjibelski2018sequence}. Despite the centrality and age of
pairwise alignment, ``a major open problem is to implement an algorithm with linear-like
empirical scaling on inputs where the edit distance is linear
in~$n$''~\citep{medvedev2022theoretical}.

% Near-quadratic worst case
Alignment accuracy affects the subsequent analyses, so a common goal
is to find a shortest sequence of edit operations (insertions, deletions, and
substitutions of single letters) that transforms one sequence into the other.
Finding such a sequence of operations is at least as hard as computing the \emph{edit
distance}, which has recently been proven to not be computable in strongly
subquadratic time, unless SETH is false~\citep{backurs2015edit}. Given that
the number of sequencing errors is proportional to the length, existing exact aligners are
limited by quadratic scaling not only in the worst case but also in practice.
This is a computational bottleneck given the growing amounts of biological data
and the increasing sequence lengths~\citep{kucherov2019evolution}.

Sequence alignment is a class of combinatorial problems that is of primary
importance for analysis of genomic data. Algorithms and tools for alignment have
been thoroughly developed and routinely used for genome assembly, RNA
quantification, detecting splicing, oncology, multiple sequence alignment (MSA),
and evolutionary biology. Types of sequence alignment include global alignment,
semi-global alignment, alignment, local alignment, and others. For each type, a
common tradeoff that had to be done is between the alignment accuracy and the
performance to find it.

% graph reference
An additional difficulty is the fact that in the
upcoming pangenomic era, these algorithms must be also applicable to complex
graph structures. For more than 60 years, a linear sequence has been extremely
useful as a representation of a single genome. The affordability of sequencing
technologies enables not only to sequence genomes deeper but also to sequence
many genomes (e.g. of organisms or single cells), building a pangenome (an
abstracted genome that represents the genetic variation of a whole clade). The
shift towards population studies in the last decade motivates the adoption of
graph data structures which serve as compressed representations of collections
of related genomes (genomes are paths in the graph).

% \A context 
An optimal alignment can naturally be represented as a shortest path in an
alignment graph (equivalent to the DP table). In order to find such a shortest
path with minimal exploration, we instantiate the \A algorithm with a novel
heuristic function based on the unaligned parts of the sequences. This
additional information is a problem-specific heuristic function and it heavily
determines the efficiency of the search. For any explored state by \A, this
heuristic function should compute a lower bound on the remaining path length, or
more specifically, the minimal cost of edit operations needed to align the
remaining sequences.

%only optimal alignment in this thesis
%asymptotics analysis
%????? linear I/O but quadratic optimal

% Accuracy and Metrics
The number of possible ways that two sequence can be aligned grow exponentially
with length. The usual underlying question to finding ``correct'' alignments.
Regarding the precision of alignment, one is usually interested in base-to-base
(aka letter-to-letter) correspondence between the sequences, even though for
some applications a less detailed solution is sufficient: only the similarity
between sequences or the location where a read maps to a reference. Exact
alignment is only useful for very short sequences (often kmers), and for all
other cases the optimized metric may be hamming distance, edit distance (unit
costs), Levenshtein distance, affine costs, convex and concave costs, general
costs and others. 

% Problem statement
Depending on the the number of aligned sequences, there is pairwise alignment
and multiple sequence alignment (MSA). Depending on the parts of the sequences
that are aligned to each other, we differentiate global, local and various
semi-global alignemnts. There are generalizations to sequence-to-sequence
alignment, including aligning to nonlinear structures, such as directed acyclic
graphs, DAGs, general graphs and others. These structures are nowadays becoming
more common as a compressed form of representing a set of references to which a
sequence can be aligned. Often, one best alignment is suefficient but finding
several best (top-K) alignments. In the context of read alignment, a set of reads
is aligned to the same reference sequence so an indexing procedure is often
useful for the performance.

We specifically consider the alignment of a set of reads to a general graph, and
the global pairwise alignment.

Existing optimal algorithms are based on dynamic programming (DP) and
run in quadratic time (assuming that the number of errors is proportional to the
length)

we employ the \A algorithm which is an \emph{informed search} algorithm.
TODO: a case for the informed algorithms

% Heuristics for alignment
Both for sequence-to-sequence alignment and sequence-to-graph alignment,
heuristics are employed to keep alignment
tractable~\cite{altschul_basic_1990,langmead_fast_2012,garrison_variation_2018},
especially for large populations of human-sized genomes.
%
% Importance of optimal alignment
While such heuristics find the correct alignment for simple references, they
often perform poorly in regions of very high complexity, such as in the human
major histocompatibility complex (MHC)~\cite{dilthey_improved_2015}, in complex
but rare genotypes arising from somatic-subclones in tumor sequencing
data~\cite{harismendy_detection_2011}, or in the presence of frequent sequencing
errors~\cite{salmela_lordec_2014}.
%
Importantly, these cases can be of specific clinical or biological interest, and
incorrect alignment can cause severe biases for downstream analyses. For
instance, the combination of high variability of MHC sequences in humans and
small differences between alleles~\cite{buhler_hla_2011} leads to a risk of
misclassifications due to suboptimal alignment. Guaranteeing optimal alignment
against all variations represented in a graph is a major step towards
alleviating those biases.

%\section{Optimal alignment}
Finding an optimal alignment requires a conceptually different approach than
finding an approximate alignment. Instead of finding \emph{one} good alignment,
finding an optimal alignment requires proving that \emph{all} other
exponentially-many alignments are not better.

Comparing one sequence to another is a basic combinatorial problem that has
several variations (shown on the right), each applicable in computational
biology. Needleman-Wunsch (1970)  and Smith-Waterman (1981) are dynamic
programming (DP) algorithms that serve as base solutions for global (or
computing edit distance of two strings) and semi-global alignments (or alignment
when a set of sequences is being aligned). Given that there is both biological
and technical variation in the data, a biologically plausible alignment is one
that minimizes the corresponding differences (e.g. insertions, deletions and
substitutions), so metrics based on edit distance are usually used. Backurs and
Indyk (2015) showed that even calculating the edit distance between two
sequences (without finding an alignment), is not generally solvable in
strongly-subquadratic time. Moreover, even for related sequences of lengths n
and m and edit distance s, the fastest optimal global (Marco-Sola et al., 2021;
Šošic and Šikic, 2017)) and semi-global aligners (Rautiainen et al., 2017) scale
quadratically when the edit distance increases with the length, which is the
case for sequencing errors and biological variation: O(s*min(n,m))=O(enm) and
O(nm), respectively, where e is the error rate (Navarro, 2001). In the age of
big data and long reads (e.g. PacBio, ONP), this quadratic scaling with length
is prohibitive, so the algorithms with practical usage (e.g. minimap2, bwt,
kallisto) do not guarantee optimality but run in subquadratic time (Kucherov,
2019). The gap between fast and optimal global alignment has been recognized but
no optimal algorithms are known that run subquadratically for related sequences
(Medvedev, 2022a). The interest towards genome graphs keeps increasing with the
first International Genome Graph Symposium being held this year in Ascona,
Switzerland (2022). The benefits of using graph references representing
biological variation has been demonstrated to increase the alignment quality
(Garrison et al., 2018). The transition towards graph references only aggravates
the computational issues owing to the potentially complex graph topology (Equi
et al., 2019). The optimal algorithms used in computational biology explore the
search space of possible alignments in an uninformed fashion: by aligning a
prefix of one sequence to a prefix of the other. This contrasts with the
informed search algorithms such as the algorithm by Hunt and Szymanski (1977)
solving the longest common subsequence (LCS) problem (a special case of the edit
distance alignment). Sequence alignment can naturally be formulated as a
shortest path problem solvable by Dijkstra’s algorithm (Ukkonen, 1985). \A is an
informed generalization of Dijkstra’s algorithm (Hart, 1968) but it has not been
successfully applied to sequence alignment. \A may be the missing piece in the
“a major open problem to implement an algorithm with linear-like empirical
scaling on inputs where the edit distance is linear in n” (Medvedev, 2022a).

\begin{paradox}
A long query has more information that may hint towards the best semi-global
alignment position in a reference but all optimal algorithms are strictly slower
for longer sequences.
\end{paradox}

Unlike the practical approximate algorithms, the existing optimal algorithms do
not exploit this information. As a result, all state-of-the-art optimal
algorithms take longer to map a longer query to a reference. 

\subsection*{Feasibility of optimal alignment}

There is a fundamental trade-off between perforamance and optimality guarantees:
an algorithm which is allowed to be suboptimal may exploit the lesser
restrictions for greater performance. Especially given the worst-case analysis
requiring near-quadratic runtime even to compute edit distance exactly, it is
understandable why most scholars are skeptical about faster optimal algorithms.
With our \A approach  offers a to exploits another dimensions: average case or expected case analysis.

% asymptotics
%has been solved in linear time in \citeyear{morris1970linear}~\cite{morris1970linear}.

In the direction of global alignment, optimal algorithms are commonly used in
practice, despite of their quadratic scaling. The ongoing competition between
the optimal aligners employs both algorithmic advancements and implementation
optimizations on caching, bit-parallelization, GPU.~(\cref{ch:global}).

For semi-global alignment (read alignment), common belief is that optimal
algorithms are infeasible for read alignment, especially when reads are long.
All production read aligners following the approximate seed-extend
paradigm~\cite{alser2021technology}\footnote{This study examines 107 aligners.}.

Informed search

An algorithm without an objective function may be wrong because they do not
solve the correct problem. or because they 

Algorithms that guarantee correctness can be wrong only by being given a wrong problem.

An approximate algorithm can be wrong either because it did not fullfill its
mathematical goal. reach its solve the problem because of either optimizing the
\emph{wrong} function.

Algorithm correctness is arguably a useful property which is often not simple to
guarantee. It can undoubtedly improve accuracy, especially in the case of
complex data, but still be wrong from biological point of view. This is because
of  This Nevertheless, since biology is a natural science, its  optimality
guarantees must have an additional impact on the development of the field. It
not only but allows to enjoy being wrong rather than vague. Moreove, often
problems in computational biology are ill-stated andalgorithms that approximate
algorithms that. But many algorithms in computational biology do not even have a
formal statement 

\paragraph{Suboptimal alignment}
%
In the last decades, approximate and alignment-free methods satisfied the demand
for faster algorithms which process huge volumes of genomic
data~\citep{kucherov2019evolution}. 
%
\emph{Seed-and-extend} is arguably the most popular paradigm in read
alignment~\citep{altschul_basic_1990,langmead_fast_2012,li_fast_2009}. First,
substrings (called \emph{seeds} or \emph{kmers}) of the read are extracted, then
aligned to the reference, and finally prospective matching locations are
\emph{extended} on both sides to align the full read.

While such a heuristic may produce acceptable alignments in many cases, it
fundamentally does not provide quality guarantees, resulting in suboptimal
alignment accuracy.
%
In contrast, here we demonstrate that seeds can benefit optimal alignment as
well.

\paragraph{Key challenges in optimal alignment}
%
Finding optimal alignments is desirable but expensive in the worst case,
requiring $\Oh(Nm)$ time~\citep{equi2019complexity}, for graph size $N$ and read
length $m$.
%
Unfortunately, most optimal sequence-to-graph aligners rely on dynamic
programming (DP) and always reach this worst-case asymptotic runtime. Such
aligners include \vargas~\citep{darby2020vargas},
\pasgal~\citep{jain_accelerating_2019},
\graphaligner~\citep{rautiainen_bitparallel_2019},
\hga~\citep{feng2021accelerating}, and \vg~\citep{garrison_variation_2018},
which use bit-level optimizations and parallelization to increase their
throughput.

In contrast, we follow the promising direction of using a heuristic to avoid
worst-case runtime on realistic data. To this end, \astarix rephrases the task
of alignment as a shortest-path problem in an \emph{alignment graph} extended by
a \emph{trie index}, and solves it using the \A~algorithm instantiated with a
problem-specific \prefixh. Importantly, its choice of heuristic only affects
performance, not optimality.
%
Unlike DP-based algorithms, this \prefixh allows scaling sublinearly with the
reference size, substantially increasing performance on large genomes. However,
it can only efficiently align reads of limited length.

Most of the techniques this thesis builds upon have been known for many decades
and have also been heavily motivated by applications in molecular biology. 