\subsection{Setting}
All evaluations were executed singled-threaded on an Intel Core i7-6700 CPU running
at 3.40GHz.

\paragraph{Reference graphs and reads}
We designed three experiments utilizing three different reference graphs (in
\cref{TRIEtab:results}). The first is a linear graph without variation based on the
\textit{E.~coli} reference genome (strain: K-12 substr. MG1655,
ASM584v2~\cite{howe2019ensembl}). The other two are variation graphs taken from
the \pasgal evaluations~\cite{jain_accelerating_2019}: they are based on the
Leukocyte Receptor Complex (LRC, with \numprint{1099856} nodes and
\numprint{1144498} edges), and the Major Histocompatibility Complex (MHC1, with
\numprint{5138362} nodes and \numprint{5318019} edges).
%
We note that we do not evaluate on de Brujin graphs, since \pasgal does not
support cyclic graphs.

%\paragraph{Reads}
For the \textit{E.~coli} dataset we used the ART tool~\cite{huang_art_2012} to simulate an
Illumina single-end read set with \numprint{10000} reads of length 100. For the LCR and
MHC1 datasets, we sampled \numprint{20000} single-end reads of length 100 from the already
generated sets in~\cite{jain_accelerating_2019} using the
Mason2~\cite{holtgrewe_mason_2010} simulator.

For \dijkstra and \astarix, the runtime complexity depends not only on the data
size, but also on the data content, including edit costs. More accurate
heuristics lead to better \A performance~\cite{pearl_discovery_1983}, which is
why we evaluate \astarix with costs corresponding more closely to Illumina error
profiles: $\Delta=(0,1,5,5)$. We apply all described optimizations.
% to, except
%\cref{TRIEsubsec:speedup-heuristic,TRIEsubsec:partition} which are applicable
%only to \astarix.

\paragraph{Metrics}
As all aligners evaluated here are provably optimal, we are mostly interested in
their performance.
%
To study the end-to-end performance of the optimal aligners, we use the
Snakemake~\cite{koster_snakemakescalable_2012} pipeline framework to measure the
execution time of every aligner (including the time spent on reading and
indexing the reference graph input and outputting the resulting alignments). We
note that the alignment phase dominates for all tools and experiments.

To judge the potential of heuristic functions, we measure not only the runtime
but also the number of states explored by \astarix and \dijkstra. This number
reflects the quality of the heuristic function rather than the speed of
computation of the heuristic, the implementation and the system parameters.
%"Fig. 3" (it also discusses explored states)}.
%The number of explored states is a more direct indicator for the algorithm's performance
%than the number of expanded states since the algorithm has to generate and consider
%all the neighbors of the states it expands.
%\todo{Harun: this argument only really works
%if computation of the heuristic is not a bottleneck. maybe make that more clear?}

\subsection{Comparison to optimal mappers}

% Even though there is a variety of short read-to-graph aligners, only a few are
% guaranteed to be optimal.
We compare the performance of \astarix to that of two state-of-the-art optimal
aligners: \pasgal and \bitparallel, with their default parameters.
%
We do not compare to the exact aligner of \vg as (i)~its optimal alignment
is intended for testing purposes only, (ii)~it does not provide an
interface for aligning a set of reads, and (iii)~it has been consistently
outperformed by \pasgal~\cite{jain_accelerating_2019}.

\pasgal is compiled with AVX2 SIMD support. The resulting alignments are not
expected to match exactly between the local aligner \pasgal and the semi-global
aligners (\astarix and \bitparallel) as they solve different tasks with
different edit costs. Nevertheless, in analogy with the evaluations of
\pasgal~\cite{jain_accelerating_2019}, it is still meaningful to compare
performance, assuming that the dynamic programming approach of \pasgal can be
adapted to semi-global alignment with similar performance.

Both \bitparallel and \pasgal reach their worst-case runtime complexity
independent of the edit costs $\Delta=(\cmatch,\csubst,\cins,\cdel)$. \pasgal is
evaluated using its default costs ~$\Delta=(-1,1,1,1)$ and \bitparallel is
evaluated using the only supported costs~$\Delta=(0,1,1,1)$.