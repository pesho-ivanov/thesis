\subsection{Comparison on synthetic data} \label{GLOBALsec:evals-comparison-synthetic}

\paragraph{Runtime scaling with length}
We compare our \A heuristics with \edlib and \wfa in terms of runtime scaling
with $n$ and $d$~(\cref{fig:synthetic}, extended comparison in~\cref{app:synthetic}).
%
As theoretically predicted, \edlib and \wfa scale quadratically. For small edit
distance, \edlib is subquadratic due to the bit-parallel optimization. The
empirical scaling of \astarpa is subquadratic for~$d{\leq}12$ and~$n{\le}10^7$,
making it the fastest aligner for long sequences~($n{>}30\kbp$).
%
For low divergence~($d{\leq}4\%$) even the simplest \SH scales near-linearly
with length~(best fit~$n^{1.05}$ for $n{\le}10^7$).
%
For high divergence~($d{=}12\%$) we need inexact matches, and the runtime of \SH
sharply degrades for long sequences~($n{>}10^6\bp$) due to spurious matches.
This is countered by chaining the matches in \CSH and \GCH, which
expand linearly many states~(\cref{app:expanded}).
\GCH with DT is not exactly linear due to state reordering and high
memory usage~(\cref{app:timing}).

\paragraph{Performance}
\astarpa is ${>}300\times$ faster than \edlib and \wfa for $d{=}4\%$ and
$n{=}10^7$~(\cref{fig:scaling-n}). For $n{=}10^6$ and $d{\leq}
12\%$, memory usage is less than $500\mb$ for all heuristics~(\cref{app:memory}).
