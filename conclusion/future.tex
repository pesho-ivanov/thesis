\section{Future work}

We foresee a multitude of extensions and optimizations that may lead to
efficient global aligning for production usage.

Approximate relaxations
Practical: AStarix2, lowering the \A constant
Pangenomics: The non-linear structure are additional dimensions of data complexity. And
another challenge for the scalability which is good.

\begin{enumerate}
    \item \emph{Performance.} The practical performance of our \A approach could
        be improved using multiple existing ideas from the alignment domain:
        diagonal transition method, variable seed lengths, overlapping seeds,
        combining heuristics with different seed lengths, gap costs between
        matches in a chain~\citep{ukkonen1985algorithms,wilbur1984context}, more
        aggressive pruning, and better parameter tuning. More efficient
        implementations may be possible by using computational
        domains~\citep{spouge1989speeding}, bit-parallelization~\citep{myers1999fast},
        and SIMD~\citep{marco2021fast}.
    \item \emph{Generalizations.} Our method can be generalized to more
        expressive cost models (non-unit costs, affine costs) and different alignment
        types (semi-global, ends-free, and possibly local alignment).
    \item \emph{Relaxations.} Abandoning the optimality guarantee
        enables various performance optimizations. Another relaxation
        of our algorithm would be to validate the optimality of a given alignment more
        efficiently than finding an optimal alignment from scratch.
    \item \emph{Analysis.} The near-linear scaling behaviour requires a thorough
        theoretical analysis~\citep{medvedev2022limitations}. The fundamental
        question that remains to be answered is: \emph{What sequences and what
        errors can be tolerated while still scaling near-linearly with the
        sequence length?} We expect both theoretical and practical contributions
        to this question.
\end{enumerate}

multiple paths
outside of biology
general framework for optimization
MSA

For \dijkstra and \astarix, the runtime complexity depends not only on the data
size, but also on the data content, including edit costs. More accurate
heuristics lead to better \A performance~\cite{pearl_discovery_1983}

% paper-trie; Scaling difficulties.
We expect that \astarix can be scaled further, to both (i)~bigger graphs and
(ii)~longer and noisier reads. Scaling \astarix may require a combination of
(i)~the development of more clever heuristic functions (by leveraging existing
work on \A and edit distance) and (ii)~algorithmic optimizations. We note that
if desired, a (sub-optimal) seeding step could speed up \astarix by
pre-filtering the starting positions, analogously to other practical aligners.

% paper-seed
The memory usage is currently limiting the application of \astarix for bigger
references due to the size of the trie index. A remaining challenge is designing
a heuristic function able to handle not only long but also noisier reads, such
as the uncorrected PacBio reads that may reach 20\% of mistakes. Possible
improvements of the seed heuristic may include inexact matching of seeds,
careful choice of seed positions, and accounting for the seeds order.

P1: Develop the AStarix sequence-to-graph mapper from prototype to production As
our previous work demonstrates, scaling optimal A* alignment to long sequences
and high error rates relies on various non-trivial algorithms, data structures
and optimizations. In order for AStarix to become of practical importance, it
must be comparable to not only optimal mappers but to approximate ones as well –
this includes tolerating more errors, lowering the runtime and memory
consumption, and supporting features. Tolerating errors. We observe two
qualitatively-different modes in which the A* explores the state space: linear
and quadratic. The mode of exploration is mainly determined by the ability of
the seed heuristic to “compensate” for the type and amount of errors. When the
heuristic cannot cope with the errors, A* has to continue exploring without the
aid of the heuristic (similar to Dijkstra): for long indels, the exploration
becomes locally quadratic (around the indel), and for too high error rate it
becomes globally-quadratic (because of the accumulating insufficiency of the
seeds). By tolerating errors, we mean the ability of the exploration to stay
linear or near-linear. Currently, AStarix supports 2-4\% errors on short reads
and only 0.3\% on HiFi reads, whereas our recent developments on global
alignment demonstrated the potential to tolerate error rate to 25\% using match
pruning, inexact matching, seed chaining. Developing these features in the
semi-global setting is not trivial because of the added complexity of crumbs and
the trie index but we do not envision any fundamental reasons against adopting
them. A natural approach to tolerating long indels, well known in the
bioinformatics community, is to generalize the edit distance metric to affine
costs in order to match the error model more closely. This extension is
algorithmically simple and consists of or there are longer indels. affine costs
for, inexact matches Memory optimization. The main memory bottleneck is
currently the trie index (which would take >90\% of the memory given a standard
compressed genome graph representation) so our primary priority is
algorithmically reduce the number of nodes in the trie and then implement it
efficiently. Currently, it is used with two separate functions: 1) to find all
seed matches, and 2) to allow the search A* to explore the whole reference only
implicitly by abstracting together the reference location reachable with the
same prefix. The first function is efficiently solvable by using the positional
Burrows-Wheeler transform (gBWT) to find exact seed matches and, in the case of
inexact matches, to pre-generate all kmers at distance 1 from the seeds and
invoke gBWT separately for each. The second function requires a trie but if
possibly not a over the whole graph, only pointing to those reference locations
which hold at least one crumb: otherwise the A* search will surely be quadratic
in which case the fallback options are to either refuse to align the read (which
is still optimal but incomplete), or find an alignment by explicitly considering
all starting locations (which could be done faster using another tool). We
foresee that building a separate “slim” trie per query will bring orders of
magnitude of shrinkage of the trie, making it proportional only to the query
length, and not the reference size. Additionally, a compressed implementation of
the trie and the reference graph has the potential to lower the current memory
usage by an additional order of magnitude. Runtime optimization. For small error
rate (0.3\%) and long reads (30 kbp), the bottleneck for the runtime is the
amount of crumbs. To effectively skip the work for placing most of the crumbs,
the placement of different seeds could be done together in one backward
traversal – this is expected to eliminate most of the work for placing crumbs on
the optimal path.  Another approach is to also “jump over unitigs” when placing
crumbs in the backwards traversal, and “carry” crumbs in the forwards A* search
in order to compensate for the skipped ones. A major optimization in the case of
high error rate, is to adapt the match pruning that we have developed for the
global alignment case. Features. By discussing AStarix on conferences, we have
figured out that extension alignment (very similar in the approach to global
alignment) is of great interest for its reusability in the seed-and-extend
paradigm that other aligners follow. Evaluation. The dataset for evaluation
ideally includes bigger graphs, noisy long reads (e.g. ONP, PacBio), reads with
bigger indels. The comparison should be not only to optimal mappers but also to
approximate oces. Potential risks. The preliminary experiments demonstrate
sublinear scaling (n0.2) with the reference size but since this is an empirical
result, it may also deteriorate for bigger graphs. Some of the optimizations may
not provide the full expected effect or the bottleneck they would resolve may
not yet be current. M1: Usage of AStarix by at least one bioinformatics group
with novel data This milestone is crucial for the adoption of AStarix by the
broader community. The milestone does not depend on the full completion of P1.

P2: Derive theoretical guarantees for the runtime scaling of A* alignment Two
equal sequences can be aligned for linear time, whereas two general sequences
cannot be aligned strongly-faster than quadratically (Backurs and Indyk, 2015).
There is a knowledge gap for the computational limitations of related sequences
(Medvedev, 2022a) which may benefit for various statistical approaches different
from the worst case asymptotic analysis and the empirical investigation
(Medvedev, 2022b). Our strong empirical results on scaling with increasing
sequence length and error rates, together with our intuition from the internals
of our A* algorithms, hint towards much stricter theoretical bounds on the
expected computational costs. Such theoretical results may also be of general
interest outside of the computational biology community. Our approach to proving
theoretical bounds is likely to be tightly related to the term potential (of a
seed heuristic function) which is a measure of the ability of a specific seed
heuristic instantiation (i.e. for fixed seed length, etc) to punish for future
errors before exploring them. The analysis should also account for the cost for
computing the heuristic (including amortized precomputation and querying) since
infinite resources on it can result in an oracle but also destroy the total
performance. The risks of such analyses include the potential inability to
account for data and error models (random reference sequence and uniform error
model) that are realistic enough. Global alignment. Our intuition on the scaling
of the explored states includes several parameters: the seed heuristic potential
and the number of errors. Informally speaking, for each error that is not
compensated by the potential, the A* search will explore another layer of states
that are 1 more distant from the diagonal. This is also theoretically and
practically true for the special case of A*, Dijkstra, which has potential 0 and
thus reaches O(ns) where s is the overall number of errors. Our empirical
results demonstrate that a near-linear runtime scaling is practically possible
up to very long sequences (100 Mbp) for error rates of 10\%. Mapping. In
addition to the computational costs for aligning a sequence to another sequence,
mapping has the burden of localization of the best mapping. Our intuition behind
his localization cost is related to to usage of A* on the trie: for each error
that the A* potential does not compensate for, the exploration would get one
lever deeper in the trie, thus exploring expected 4x more states. This is an
interesting observation since it hints to an exponential scaling with error
rate, which is not asymptotically possible because of the quadratic worst case,
but may be the case near the best-case. In such a case, a type of a sigmoid
would possibly describe the number of explored states as a function of the
number of errors.

P3: Extend graph references to probabilistic framework Probabilistic
interpretations arise in different places among the alignment problems. Phred
values. Sequencing machines report a standardized score per nucleotide that
estimates the probability of that nucleotide being wrong. This information is
currently largely ignored and very valuable for highly erroneous sequencing
technologies. Extending the edit distance metric to account for phred values
should be directly applicable and may even benefit the performance of the A*
algorithm due to the better correspondence between the scores and the error
model. Weighted genome reference. A topic for current discussions in the
pangenomics field is whether to add more genomes to the reference graph or to
keep the reference unbiased (by unbalanced number of entries for different
variations, or by adding genomes from other populations). One reason for such
discussions are the memory and runtime limitations, but the accuracy of
alignment is not less important. A weighting of the graph may be useful as a
soft tradeoff. HMM. HMM queries have been useful in the context of microbial
sequencing (Shlemov and Korobeynikov, 2019). Possibly, A* can be extended to
handle HMM queries instead of linear sequences. The current solutions are
prohibitively slow and AStarix is expected to greatly accelerate the optimal
alignment after being generalized to probabilistic queries. MAPQ. The mapq value
may be calculated more precisely if accounting for the probability estimates.

P4: Explore the applicability of A* to local alignment Our previous work has
been focusing on semi-global alignment (mapping) and global alignment (and
extension). The issue with extending the A* approach to local alignment is
two-fold: The search for the best local alignment is being reset when the
current score becomes negative – in other words, negative scores are crucial for
local alignment but not directly applicable to Dijkstra and A*. A potential
solution may follow the approach of Jonson’s algorithm which reweights the graph
to only non-negative edges as long as there are no negative cycles (Johnson,
1977). For semi-global and global alignments, the whole query is being aligned,
which is a useful property for the admissibility of the seed heuristic, since
each seed is guaranteed to be aligned eventually. In the case of local
alignment, some seeds may not be aligned. Possible workarounds have to be
explored. A solution to local alignment may as well be applicable to the split
alignment mode when “teleportations” are allowed. Another application of local
alignment is to align reads without trimming their ends from adapters first.

P5: Explore the applications of machine learning to generating better admissible
heuristics Tuning parameters is generally hard and it has been problematic for
the seed heuristic as well. One potential place for runtime improvement is to
carefully choose the seed heuristic parameters: seed length and allowed number
of errors per match. Usually machine learning methods do not provide correctness
guarantees about the produced results. Nevertheless, since the parametrization
of the seed heuristics influences only its performance and not its admissibility
and optimality of the results. Additionally, the seed heuristic parameters could
be chosen or modified dynamically, during the A* search. Reinforcement learning
may provide a reasonable method to tuning the parameters in real-time. My
expected visit to Prof. Šikić group may result in substantial progress on this
work package.

P6. Explore the applications of finding K-best alignments which is trivially
achievable in A* framework. A natural extension of the shortest path algorithms
is to find not one shortest path, but K-shortest paths. One application of the
K-best alignments is the computation of the MAPQ mapping score which is based on
the alignment costs of the K-best alignments and provides an estimation on the
certainty of the best alignment. Potentially, there may be other applications.

P7: Explore joint mapping of a set of sequence to a graph The reads to be mapped
to a reference genome are highly correlated since they usually come from the
same biological sample. On the other hand, they can be biased according to the
reference genome, due to biological variation. Ideally, a clever alignment
algorithm would reconstruct this biological variation and align the reads to the
corrected reference. This problem is ill-posed and needs careful consideration
to develop a theory/metric. Another complication is computational: aligning even
a single query to a graph that is allowed to change may require exponential time
with the query length.

P8: Explore A* for multiple sequence alignment (MSA) Existing approaches to MSA
using A* consider pairwise edit distances, which do not considerably accelerate
the alignment. A simultaneous seed match (anchor) within several sequences may
provide much bigger penalties for suboptimal paths.

P9: Explore suboptimal relaxations for performance gain Various relaxations of
the heuristic admissibility, variants of A*, windowing the search (dropping
expanded states that are too far behind the exploration head), have the
potential to greatly increase the performance at the price of alignment
optimality. This work package may be useful for the performance and thus the
practical adoption of the algorithm but we prefer first gaining the performance
from the obvious promising optimality-preserving optimizations.

% +asymptotic analysis
Our presented method has several limitations:
\begin{enumerate}
  \item \emph{Complex regions trigger quadratic search.} Since it is unlikely
        that edit distance in general can be solved in strongly subquadratic
        time, it is inevitable that there are inputs for which our algorithm
        requires quadratic time.  In particular, regions with high error rate,
        long indels, and too many matches~(\cref{GLOBALsec:limitations}) are
        challenging and trigger quadratic exploration.
  \item \emph{High constant in runtime complexity.} Despite the near-linear
        scaling of the number of expanded states~(\cref{GLOBALsec:expanded}),
        \astarpa only outperforms \edlib and \wfa for sufficiently long sequences
        (~\cref{GLOBALfig:scaling-n}) due to the relatively high computational constant
        that the \A search induces.
  \item \emph{Complex parameter tuning.} The performance of our algorithm
        depends heavily on the sequences to be aligned and the corresponding choice of
        parameters (whether to use chaining, the seed length $k$, and whether to use
        inexact matches $\spot$). The parameter tuning (currently
        very simple~(\cref{GLOBALsec:evals-setup}) may require a more comprehensive
        framework when introducing additional optimizations.
  \item \emph{Real data.} The efficiency of the presented algorithm has high
        variability on real data~(\cref{GLOBALsec:evals-comparison-hg}) due to high
        error rates, long indels, and multiple repeats (demonstrated
        in~\cref{GLOBALfig:limitations}). Further optimizations are needed to align
        complex data.
\end{enumerate}

\paragraph{Generalizing the distance metric}
%\dictum[Freeman Dyson]{%
%   It is better to be wrong than to be vague.}
%\vskip 1em

In this thesis we were optimizing edit distance. 
Big gaps (indels) in biological sequences motivate affine and concave costs. Local alignment is
\cite{arslan2001new}.