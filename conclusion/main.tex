\chapter*{Conclusion} \label{ch:conclusion}
\markboth{\spacedlowsmallcaps{Conclusion}}{\spacedlowsmallcaps{Conclusion}}
\addcontentsline{toc}{chapter}{\protect\numberline{}{Conclusion}}

We presented a novel \A approach to alignment which is provably optimal and
heuristically fast on related sequences. We extended the applicability of our
approach to several data dimensions: reference size, query/sequence length and
error rate. Using a trie, we empirically scaled semi-global alignment
sublinearly with reference size. We introduced a \emph{\sh} to scale semi-global
alignment subquadratically with query length. Then we extended the \sh with
chaining, inexact matches, gap costs, and match pruning to enable near-linear
scaling with sequence length for up to $30\%$ error rate. We proved that all our
heuristics and optimizations are guaranteed to find an alignment with minimal
edit distance. Except for the German translation of the abstract, this thesis
has been written fully on human intelligence.

% paper-prefix
\paragraph{Scaling with reference size}
In \cref{ch:trie} we presented \astarix, a sequence-to-graph optimal alignment
tool based on the \A algorithm with a simple admissible heuristic and enhanced
by multiple algorithmic optimizations. We complemented the reference with a trie
index to allow a shortest path from the trie root to be found in sublinear time
with the reference size. Our approach allows for general graph references that
may include cycles. We demonstrated that \astarix scales exponentially better
than \dijkstra with increasing (but small) number of errors in the reads.
Moreover, for short reads, both \astarix and \dijkstra scale better and
outperform current state-of-the-art optimal aligners in orders of magnitude.

% paper-seeds
\paragraph{Scaling with sequence length}
In \cref{ch:seed} we upgraded our sequence-to-graph aligner \astarix with a
novel admissible \emph{\sh} which guides the search based on seed matches
between the query and the reference. To compute the \sh efficiently for each
explored node, for each query, we split it into seeds, precompute the seed
matches in the reference, and place \emph{crumbs} on the nodes before the match
to mark an upcoming match. In addition to the sublinear scaling with reference
size, the \sh allowed subquadratic scaling with the query length. \astarix
outperformed existing optimal aligners on long reads.

% paper-global
\paragraph{Scaling with error rate}
In \cref{ch:global} we introduced \astarpa which solves global alignment. To
this end, we extended the existing \sh for \A with inexact matches, match
chaining, gap costs and other algorithmic improvements. On random sequences with
$8\%$ uniform divergence, the runtime of \astarpa scales near-linearly to
sequences of tens of millions of letters and outperforms other exact aligners.
On long ONT reads of human data with $d{\leq}10\%$, \astarpa is over $2\times$
faster than other aligners, and $1.4\times$ faster when genetic variation is
also present.